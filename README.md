# Binary Classification Project
T1.1: Data Description & Exploratory Data Analysis
The dataset contains 5,471 samples with 4,124 features, which are numerical measurements representing gene expression levels. The target variable is binary, and thus each sample belongs to one of two categories: TREG cells (binary label: 1) and CD4+T cells (binary label: 0). Notably, the dataset is not balanced, due to more samples of CD4+T cells (3,356) compared to TREG cells (2,115). Imbalanced datasets can cause models to become biased towards predicting the majority class (CD4+T) while neglecting the minority class (TREG). Hence, solely focusing on maximising accuracy may be insufficient to evaluate model performance. Although the ratio is approximately 1.59 to 1 for CD4+T to TREG cells, implying that the classes are only mildly imbalanced, we still utilise other performance metrics for models such as F1 Score and balanced accuracy, which account for both classes rather than only relying on the overall accuracy. 
The main challenge with this dataset is its high dimensionality; training a model on 4,124 features may result in overfitting, where the model performs well on the training data but poorly on new, unseen data. Hence, we conducted exploratory data analysis (EDA) to better understand the gene expression data, with a focus on identifying information relevant to classifying the samples as either TREG or CD4+T cells. The magnitude of gene expression levels in a given cell can be a key identifying factor for the cell type, and thus we computed the variation in gene expressions across both classes. Figure 1 shows the normalised variability of gene expression levels, with the corresponding summary statistics. 
The middle 50% of the gene expression variability is concentrated in a narrow interquartile range (0.069 - 0.283), with low mean and median values at 0.180 and 0.152. This indicates that most gene expression levels are not highly variable but rather across cell types, and thus play a less significant role for the classification task. However, given that the mean variability is slightly higher than the median variability, this suggests a slightly right-skewed distribution, due to the presence of the outliers with high variance above 0.6. We are 
interested in these highly variable gene expressions residing in the top 25% of the distribution, because they are more likely to contribute meaningfully to distinguishing between the two cell types. Hence, focusing on genes in the upper quartile can aid feature selection to combat the high dimensionality of this dataset.
 
Figure 2: Boxplots to showcase the variability captured by various subsets of gene expressions
To identify a smaller subset of highly variable and thus informative genes, we ranked the gene expressions by variability and evaluated the total variability captured by the top 20, 50 and 100 most variable genes. Figure 2.1 shows that the top 20 genes exhibit the highest variability and already contain the outliers seen in Figure 1 (blue boxplot), with their variability spanning from 0.6 to 1. These top 20 genes capture substantially more variance than the next 150 genes, shown by the genes ranked from 20 to 200 (orange boxplot), as they only capture variability between 0.4 to 0.6. This indicates diminishing returns in the variability captured as more genes are added; especially seen in the green boxplot denoting genes >200, as they collectively only capture minimal variability between 0 to 0.4. Similarly for Figures 2.2 and 2.3, the top 50 and 100 ranked genes cover most of the high variability (> 0.5 and > 0.4), while subsequent subsets demonstrate increasingly minimal variance, as seen by the reduced spread of the orange boxplots between Figures 2.2 and 2.3. Based on Figure 2.3, we conclude that the top 100 ranked highly variable genes would be sufficient to capture useful patterns in the data for classification, while enabling a parsimonious model; balancing information gain and model complexity.
 
Figure 3: Violin plots for various gene expressions and their distributions in TREG and CD4+T cell types
Figure 3 highlights how gene expressions with higher variability may be biologically important features for the classification task. We observe violins plots for 4 genes, showcasing the distribution of their expression levels across TREG and CD4+T cells. Firstly, the distribution of IL7R (variance = 0.76) in TREG cells is relatively concentrated around lower expression values, with the density sharply decreasing at higher values. On the contrary, the median is noticeably higher in CD4+T cells and distribution of the gene is concentrated at higher values. Therefore, IL7R could be a strong candidate for distinguishing between these cell types due to the gene being more predominantly expressed in CD4+T cells. Secondly, for BIRC3 (with a moderately high variance of 0.55), there still exists an observable distinction between the gene’s expression levels in both cell types; it is more characteristic of TREG cells than CD4+T cells, due to the higher density at large expression values for TREG. However, when examining genes with low to no variability in expression levels, such as H2AFJ and AHR (variances 0.32 and 0), it becomes challenging to determine whether the genes are more pronounced in one of the two cell types. These genes have relatively small medians, with extremely narrow distributions around high gene expression levels and appear identical in terms of their violin plots for both TREG and CD4+T. Hence, this EDA showcases that genes with highly variable expression levels are more likely to serve as informative features, while genes with low variability may have minimal to no predictive power for the classification task.
 
Figure 4 investigates the correlations between the gene expression levels and the binary cell type (TREG: 1, CD4+T: 0) which appear to be approximately normally distributed and centred around 0. This suggests that most of the gene expressions do not exhibit extreme correlations with either of the cell types; in fact, they exhibit little to no correlation, implying that they are less relevant for classification. Thus, we focus on tails of the distribution, which represent genes with moderate to high correlation with the cell type, and visualise the 30 most positively and negatively correlated gene expression levels with the binary cell type in Figure 5. The heatmap demonstrates genes that may be potentially important markers for TREG and CD4+T respectively. Overall, our EDA has shown that a certain subset of genes (highly variable, correlated) may be more informative for the classification task than others.
Task 1.2: Training and Evaluating Classifiers
We primarily trained six models on the original dataset - LDA, QDA, Logistic Regression, Random Forest, Gradient Boosting, k-NN, and SVM, with a 80-20 split for the train and test data. We standardised the features prior to training, to prevent certain genes from dominating the learning process due to larger expression levels. Secondly, we trained these models on a smaller, PCA-transformed dataset with 10 components to reduce the dimensionality of the dataset and observe whether these components successfully retain meaningful variance from the gene expression data. We performed hyperparameter tuning for these two sets of models using GridSearchCV with stratified 5-fold cross validation to optimise the F1 score for a thorough evaluation of the models across predefined parameter grids for each model. This validation technique accounts for the mild class imbalance in our dataset by ensuring that each class gets fair representation in the training and validation phase. We designed the parameter grids to balance model performance, computational efficiency and convergence. For example, we tuned LDA and QDA on the shrinkage and regularisation parameters respectively, logistic regression on the solver and maximum iterations and k-NN on the number neighbours, weighting schemes and distance metrics. For Random Forest and Gradient Boosting, we used “sqrt” and “log2” for the maximum features parameter for the non-PCA dataset, to handle the large number of features by reducing overfitting and speeding up the training. For the PCA dataset with only 10 variables, we used a more granular grid ranging from 0 to 10 features with a step size of 2. We also tuned on the number of estimators and maximum depth to allow for model flexibility and prevent overfitting. Tables 1 and 2 summarise the performance of tuned models with and without PCA.
 
Most models achieve higher F1 scores when trained on the original data (Table 1), compared to the PCA-transformed data (Table 2). LDA and Gradient Boosting exhibit the highest F1 score at 0.951 for the non-PCA model, with Gradient Boosting performing best overall with the highest accuracy (0.965), balanced accuracy (0.957) and AUC (0.994), making it the most robust model for distinguishing between the two cell types. LDA and SVM follow closely, only differing by 0.001 on all metrics and thus equally well-suited for classification. Logistic Regression and Random Forest perform well, but with lower F1 scores at 0.938 and 0.914. Meanwhile, k-NN and QDA struggle to perform well with the lowest F1 scores at 0.534 and 0.537 respectively. However, considering the PCA model shown in Table 2, applying PCA significantly improves the performance of k-NN and QDA, lifting F1 Scores to 0.901 and 0.937 respectively. Also for Logistic Regression, applying PCA improves its performance on the test set from an F1 Score of 0.938 to 0.946, making it the third highest F1-scoring model. This could be explained by PCA reducing some multicollinearity among the high-dimensional features, resulting in more stable estimates and better model performance for Logistic Regression. The remaining models still perform quite well, implying that the feature set could be reduced to fewer components to capture the maximum variance in the data, as also identified in our EDA. However, most models exhibit slightly lower performance with PCA than without, suggesting that PCA may be discarding certain features relevant for classification. Overall, LDA, Gradient Boosting, SVM and Logistic Regression handle high-dimensional data most effectively, yielding the highest performance metrics for the non-PCA model, while Logistic Regression with PCA results in slightly better generalisation, making it the superior model for PCA data.
 
Figure 6: ROC Curves for the test data plotted for models without and with PCA
The ROC curves for most non-PCA models show excellent performance of classifiers with AUC values around 0.99; LDA, Logistic Regression, Gradient Boosting, Random Forest and SVM are able to distinguish very well between the two cell types. However, k-NN and QDA show poor classification performance without PCA, with QDA only acting as well as a random classifier with an AUC of 0.5. When PCA is applied, the performance of k-NN and QDA drastically improve, as shown by the new ROC curves and AUC scores of 0.97 and 0.99 respectively. However, an important point to note is that applying PCA increases false negatives (FN) and decreases true positives (TP) for most models, resulting in more misclassified cells. This supports our observations from Tables 1 and 2, that PCA might be simplifying the feature space at the cost of removing certain features that help with identifying true positives, and thus the tuned models with non-PCA are better for classification.
Task 1.3: Advanced Techniques to Improve F1 Score
Based on the results shown above for the tuned models, we selected three models with high F1 scores with the goal of further improving their F1 scores as it gives a more comprehensive evaluation of the models, given that we have a mildly imbalanced dataset. The chosen models include Logistic Regression, LDA, and SVM, with a variety of techniques applied to them: regularisation, bagging, and boosting. 
Logistic Regression was good for understanding the model, and it performed well too. LDA handled high-dimensional data very well, while SVM excelled at capturing complex patterns. We decided to proceed with the original dataset without PCA. This way, we kept all the features and without losing any important information. It turned out to be better for LDA and SVM when working with detailed biological data. Logistic Regression had an F1 score that was just a bit lower by 0.008 for the non-PCA data. Still, we used it because it was easier to interpret with the original features. We dropped other models for a few reasons: QDA had issues with collinearity, k-NN struggled with too many dimensions, Random Forest didn’t perform well, and Gradient Boosting was too resource-heavy. So, we focused on Logistic Regression, LDA, and SVM to maintain efficiency and clarity while still working to boost those F1 scores.
Considering the techniques used, we employed regularisation as it helps prevent overfitting. For Logistic Regression, we used L2 regularisation to keep the coefficients in check. For LDA, its shrinkage regularisation worked well for noisy data. SVM used a parameter called C to adjust the space between the classes. Next, bagging, or bootstrap aggregating, improved stability by training on parts of the data. For logistic regression, this means combining results from several models to reduce variance. In LDA, bagging helped too, as it trained on different samples. However, bagging is not well suited for SVM because it relies on the whole dataset for its decisions. It’s also expensive in terms of computing power. Lastly, Boosting works by paying more attention to hard-to-classify samples to boost performance. For Logistic Regression, AdaBoost made it focus on those tough cases during training. This does not work with LDA because it assumes all training samples matter equally and therefore can’t use the weights generated for Boosting to work. SVM can use AdaBoost to improve its performance by focusing on misclassified samples and adjusting weights during training.
After applying advanced techniques to improve F1 Score, we evaluated the performance of the selected models: Logistic Regression, LDA, and SVM. All three demonstrated strong performance across F1 Score, Accuracy, and AUC, with LDA (Regularisation) achieving the highest F1 Score of 0.951, effectively addressing class imbalance. Regularisation (ridge for Logistic Regression, shrinkage for LDA, and implicit for SVM) helped reduce overfitting, while Bagging stabilised Logistic Regression and LDA, although with minimal F1 Score improvement. For logistic regression boosting significantly enhanced F1 Scores than regularisation and bagging. Similarly for LDA, Regularisation stands out to be better than Bagging, although it was incompatible with LDA. Lastly for SVM, performance gains were less marked for boosting than for regularisation.
Table 5: Performance metrics after attempting to increase F1 Score
 
Overall, LDA with Regularisation emerged as the best-performing model, achieving the highest F1 Score, accuracy, balanced accuracy and AUC, as validated in the Table 5. Its F1 Score of 0.951 indicates exceptional performance in balancing precision and recall, while its balanced accuracy of 0.955 ensures fair treatment of both CD4+T and TREG classes. The shrinkage regularisation was particularly instrumental in stabilising its performance, making it a reliable and computationally efficient choice for this classification task. Therefore, LDA with Regularisation is our final, optimal classifier for predicting TREG and CD4+T cell types.
Conclusion of Task 1:
Our study aimed to classify T-cells (CD4+T and TREG) using gene expression data and advanced machine learning techniques. By conducting a thorough exploration and rigorous evaluation, we trained, tuned and evaluated six models including LDA, QDA, Logistic Regression, Random Forest, Gradient Boosting, k-NN, and SVM, both with and without PCA. We conducted hyperparameter tuning using GridSearchCV with stratified 5-fold cross-validation to optimise model performance, while Bagging, Boosting, and Regularisation methods were employed to enhance F1 scores. Among these models and approaches, LDA with Regularisation emerged as the best-performing model across all metrics, achieving an F1 Score of 0.951, accuracy of 0.965, balanced Accuracy of 0.955, and AUC of 0.993. These metrics reflect a well-balanced performance across precision and recall, highlighting the model's ability to handle the imbalanced dataset effectively. Despite these strengths, there were some limitations in our approach. LDA, while excelling in performance, lacked compatibility with techniques like boosting, limiting its adaptability. SVM bagging, although effective, was computationally intensive, requiring significant resources and time. Additionally, advanced techniques like SVM and Gradient Boosting, though powerful, were less interpretable compared to simpler models like Logistic Regression and LDA. Overall, Regularised LDA combined strong performance with computational efficiency, emphasising the ability of simpler models to outperform more complex approaches in this context. Future work should focus on enhancing model interpretability and scalability to ensure practical applications in biological and clinical settings.
